\section{Results and Discussion}

The \textit{Practicum} was able to identify the internal structure of the models used for machine learning applications, and abstract the content to create a single 32 byte indicator, that can be used as an identifier for uniquely identifying the provenance of machine learning models. The two key applications; recording the changes of the model during the training process locally, and publishing the signature to a cloud repository for verification, validation and traceability all resulted in a mechanism for recording the lifecycle of models.

Beyond looking at simple models, we were able to generate signatures for all default Keras models, as well as sample models used in competitive machine learning challenges. In all cases, we were able to generate a \textit{family tree} of the model's history, as well as an \textit{ancestor} function that identifies the original model used as the baseline for published models. Following the process presented in Figure \ref{fig:lifecycleModels}, we are able to store multiple relationships between models as they are created and published. More importantly, we are not able to remove the model from the global repository.

\begin{figure}[!t]
    \centering
    \includegraphics[width=2.5in]{flowchart-4.png}
    \caption{Lifecycle of Software Models}
    \label{fig:lifecycleModels}
\end{figure}

\subsection{Reduction in size for model identification}
The first straightforward result, is being able to produce simplified impressions of models that negate the requirement to store large binary models containing all of the weights, while still providing a utility of being able to determine that a model has changed, how it's structure changes, and which layers have been amended. Below in table \ref{table:memory} is the table of the most common models sizes, which show how much memory is required per iteration, epoch or batch if we wish to retain details of the model. As seen, it shows the high memory cost for some model, which are extracted down to less than one megabyte for the most complex models.

\begin{table}[!ht]
    \centering
    \caption{Memory Usage for Internal Model}
    \label{table:memory}
    \setlength\tabcolsep{0pt} % make LaTeX figure out intercolumn spacing
    \begin{tabular}{@{} p{2cm} p{2cm} p{2cm} p{1cm}  @{}}
        \hline
        Model & Size & Impression Size & Time\\
        \hline
        VGG16       & 528MB & 38.2kb & 4.11s \\
        DenseNet121	& 33MB & 693.8kb & 0.37s \\
        DenseNet169	& 57MB & 952.1kb & 0.53s \\
        Xception	& 88MB & 219.4kb & 0.25s \\
        ResNet50	& 98MB & 292.0kb & 0.41s \\
        ResNet50V2	& 98MB & 311.3kb & 0.42s \\
        MobileNet	& 16MB & 149.3kb & 0.17s \\
        MobileNetV2	& 14MB & 248.5kb & 0.20s \\
        \hline
    \end{tabular}
\end{table}

    Overview of Layers stored in Database
    Comparison of Model Visualisation and Summary

\subsection{Identification of Model History}

One of the most powerful elements for AI practitioners, is the ability to generate a timeline of releases based on when a model is released. In the example shown in figure \ref{fig:lifecycle_in real}, The initial model is shown preserved in both the local and remote repositories. At the end of the model training process, each individual iteration is stored internally with a parent<=>child relationship as part to training process. Once a model is ready for internal testing, it can be baselined, updating the model to point to the original base model. This is shown in the iterations in light blue below. When a model is ready for public release, then the model is baselined. We were able to provide multiple directions to deliver this be creating a parallel library that uses only the data functions. From here, we are able to produce the output below in text format that is then transfered into a visualisation tool. Demonstrations are available showing the development of this output in real time as more release are made to the family tree.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=2.5in]{lifecycle.png}
    \caption{Lifecycle of Models in Development Path}
    \label{fig:lifecycle_in real}
\end{figure}

The true power of this is being able to use the system to verify and baseline systems, so they are compliant and can be audited in line emerging standard in AI, such as the EU Artificial Intelligence Act, inspired by the work of the AI HLEG \cite{high-levelexpertgrouponaiEthicsGuidelinesTrustworthy2019}. Every subsequent model released will be added to the chain, and at anytime the model itself can be used to generate a signature while shows the history.

The final set of tools included in the Practicum provide the overview of the history. The \verb|lifecycle.get_history()| function returns the history in either the developers or the global repository of a given signature, providing the dates, basic information about the model as well as the important signature. The information for a default keras transformer training over 20 epoch is shown in figure \ref{fig:transformer}

\begin{figure}[!ht]
    \centering
    \includegraphics[width=2.5in]{learning process of transformer.png}
    \caption{Transformer Learning Process}
    \label{fig:transformer}
\end{figure}

The output of signatures is quite extensive when recording the history of training, although it has been successful in staying within the family branch. Additional functionality is provided by the \verb|lifecycle.get_ancestor()|, which shows the local root node, or the ultimate parent in the global repository. Of course, this can be applied in two directions, and the \verb|lifecycle.family_tree()| function records all children available in a nested group.


The true power of this function will be a full graphical GUI to explore the graph, and functions are avail to plot both the history (figure \ref{fig:beforeafter}) as well as an interactive tool for comparing the entire tree. The performance of both is significantly faster than any other tools for comparing the layer structure of models in real time. All objectives of being able to see the history of models, plus insight into an average layer delta have been successful.

\begin{figure}[!h]
    \centering
    \includegraphics[width=2.5in]{model_changes.png}
    \caption{Comparison of Before/After Training}
    \label{fig:beforeafter}
\end{figure}|







